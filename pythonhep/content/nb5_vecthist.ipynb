{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PURSUE Python for HEP: Vectors and Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So far, we have been using a limit set of features of the Hist library. In this notebook, we will take a closer look into this library and some of its very powerful features.\n",
    "* Additionally, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skhep_testdata\n",
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "import hist\n",
    "import vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Dimension Histogram\n",
    "\n",
    "* Numpy has basic histogramming features. It includes a function, `np.histogram`, which, when given an array of data, bins data and returns the bin heights and bin edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = uproot.open(skhep_testdata.data_path(\"uproot-Zmumu.root\"))[\"events\"]\n",
    "np.histogram(tree[\"M\"].array(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we saw briefly, Matplotlib also has some plotting features for histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tree[\"M\"].array())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* However, for specialized uses like those in HEP, the features Numpy and Matplotlib provide are limited.\n",
    "* The hist library offers advanced histogramming tools. It is built on top of boost-histogram, which is in itself a very fast histogramming library.\n",
    "* The two powerful features we will take a look at are multidimensional histograms with named axis and slicing of histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hist\n",
    "\n",
    "h = hist.Hist(hist.axis.Regular(120, 60, 120, name=\"mass\"))\n",
    "\n",
    "h.fill(tree[\"M\"].array())\n",
    "\n",
    "h.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing bins. Numbers here are NOT coordinate values, but the idx for the bin\n",
    "h[10:110].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select by coordinate value\n",
    "h[hist.loc(90):].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you rebin by a factor\n",
    "h[hist.loc(70):hist.loc(110):hist.rebin(3)].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating over a range\n",
    "h[hist.loc(80):hist.loc(100):sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Dimension Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picodst = uproot.open(\n",
    "    \"https://pivarski-princeton.s3.amazonaws.com/pythia_ppZee_run17emb.picoDst.root:PicoDst\"\n",
    ")\n",
    "\n",
    "vertex_data = picodst.arrays(filter_name=\"*mPrimaryVertex[XYZ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexhist = hist.Hist(\n",
    "    hist.axis.Regular(600, -1, 1, label=\"x\"),\n",
    "    hist.axis.Regular(600, -1, 1, label=\"y\"),\n",
    "    hist.axis.Regular(40, -200, 200, label=\"z\"),\n",
    ")\n",
    "\n",
    "vertexhist.fill(\n",
    "    ak.flatten(vertex_data[\"Event.mPrimaryVertexX\"]),\n",
    "    ak.flatten(vertex_data[\"Event.mPrimaryVertexY\"]),\n",
    "    ak.flatten(vertex_data[\"Event.mPrimaryVertexZ\"]),\n",
    ")\n",
    "\n",
    "main_art, top_art, side_art = vertexhist[\n",
    "    hist.loc(-0.25) : hist.loc(0.25), hist.loc(-0.25) : hist.loc(0.25), sum # x and y from -0.25 to 0.25, z is intregrated over\n",
    "].plot2d_full() # Allows marginal histograms along x and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Using the dimuon data we loaded from opendata, plot a 2d histogram of eta vs phi. Explain what you are looking at in the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors\n",
    "\n",
    "* We are dealing with physics data, so wouldn't it be cool to have some kind of data structure specifically made for this sort of purpose? Well, there is!\n",
    "* Suppose you want to compute $\\Delta R$. We know that this is given by\n",
    "    $$\n",
    "        \\Delta R = \\sqrt{(\\Delta \\eta)^2 + (\\Delta \\phi)^2}\n",
    "    $$\n",
    "    Now suppose you only have $p_x$, $p_y$ and $p_z$. Although you have all the information you need to compute $\\Delta R$, it is a bit annoying and you will have to do some extra computations, making your code filled with intermediate steps and forcing you to define functions that should be common. This is where Vector can help! It automatically computes these values when requested.\n",
    "* With vector, we can construct 2D, 3D and Lorentz vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vector\n",
    "\n",
    "one = vector.obj(px=1, py=0, pz=0)\n",
    "two = vector.obj(px=0, py=1, pz=1)\n",
    "\n",
    "one + two\n",
    "\n",
    "one.deltaR(two)\n",
    "\n",
    "one.to_rhophieta()\n",
    "two.to_rhophieta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = uproot.open(skhep_testdata.data_path(\"uproot-Zmumu.root\"))[\"events\"]\n",
    "\n",
    "one = ak.to_numpy(tree.arrays(filter_name=[\"E1\", \"p[xyz]1\"]))\n",
    "two = ak.to_numpy(tree.arrays(filter_name=[\"E2\", \"p[xyz]2\"]))\n",
    "\n",
    "# Changing dtype.names field\n",
    "one.dtype.names = (\"E\", \"px\", \"py\", \"pz\")\n",
    "two.dtype.names = (\"E\", \"px\", \"py\", \"pz\")\n",
    "\n",
    "# Changing view of data\n",
    "one = one.view(vector.MomentumNumpy4D)\n",
    "two = two.view(vector.MomentumNumpy4D)\n",
    "\n",
    "one + two\n",
    "\n",
    "one.deltaR(two)\n",
    "\n",
    "one.to_rhophieta()\n",
    "two.to_rhophieta()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvscikit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
